@book{trappenberg2009fundamentals,
  title={Fundamentals of computational neuroscience},
  author={Trappenberg, Thomas},
  year={2009},
  publisher={OUP Oxford}
}
@article{butts2019data,
  title={Data-driven approaches to understanding visual neuron activity},
  author={Butts, Daniel A},
  journal={Annual review of vision science},
  volume={5},
  number={1},
  pages={451--477},
  year={2019},
  publisher={Annual Reviews}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}
@inproceedings{li2014medical,
  title={Medical image classification with convolutional neural network},
  author={Li, Qing and Cai, Weidong and Wang, Xiaogang and Zhou, Yun and Feng, David Dagan and Chen, Mei},
  booktitle={2014 13th international conference on control automation robotics \& vision (ICARCV)},
  pages={844--848},
  year={2014},
  organization={IEEE}
}
@article{celeghin2023convolutional,
  title={Convolutional neural networks for vision neuroscience: significance, developments, and outstanding issues},
  author={Celeghin, Alessia and Borriero, Alessio and Orsenigo, Davide and Diano, Matteo and M{\'e}ndez Guerrero, Carlos Andr{\'e}s and Perotti, Alan and Petri, Giovanni and Tamietto, Marco},
  journal={Frontiers in Computational Neuroscience},
  volume={17},
  pages={1153572},
  year={2023},
  publisher={Frontiers Media SA}
}

@article{ghosh2009spiking,
  title={Spiking neural networks},
  author={Ghosh-Dastidar, Samanwoy and Adeli, Hojjat},
  journal={International journal of neural systems},
  volume={19},
  number={04},
  pages={295--308},
  year={2009},
  publisher={World Scientific}
}
@article{yamazaki2022spiking,
  title={Spiking neural networks and their applications: A review},
  author={Yamazaki, Kashu and Vo-Ho, Viet-Khoa and Bulsara, Darshan and Le, Ngan},
  journal={Brain Sciences},
  volume={12},
  number={7},
  pages={863},
  year={2022},
  publisher={MDPI}
}
@article{izhikevich2004model,
  title={Which model to use for cortical spiking neurons?},
  author={Izhikevich, Eugene M},
  journal={IEEE transactions on neural networks},
  volume={15},
  number={5},
  pages={1063--1070},
  year={2004},
  publisher={Ieee}
}

@book{miikkulainen2006computational,
  title={Computational maps in the visual cortex},
  author={Miikkulainen, Risto and Bednar, James A and Choe, Yoonsuck and Sirosh, Joseph},
  year={2006},
  publisher={Springer Science \& Business Media}
}
@article{niell2021cortical,
  title={How cortical circuits implement cortical computations: mouse visual cortex as a model},
  author={Niell, Cristopher M and Scanziani, Massimo},
  journal={Annual Review of Neuroscience},
  volume={44},
  number={1},
  pages={517--546},
  year={2021},
  publisher={Annual Reviews}
}

@article{antolik2024comprehensive,
  title={A comprehensive data-driven model of cat primary visual cortex},
  author={Antol{\'\i}k, J{\'a}n and Cagnol, R{\'e}my and R{\'o}zsa, Tibor and Monier, Cyril and Fr{\'e}gnac, Yves and Davison, Andrew P},
  journal={PLOS Computational Biology},
  volume={20},
  number={8},
  pages={e1012342},
  year={2024},
  publisher={Public Library of Science San Francisco, CA USA}
}

@book{bear2020neuroscience,
  title={Neuroscience: Exploring the brain, enhanced edition: Exploring the brain},
  author={Bear, Mark and Connors, Barry and Paradiso, Michael A},
  year={2020},
  publisher={Jones \& Bartlett Learning}
}

@article{goebel2004visual,
  title={Visual system},
  author={Goebel, Rainer and Muckli, LARS and Kim, Dae-Shik},
  journal={The Human Nervous System Elsevier, San Diego},
  pages={1280--1305},
  year={2004}
}

@book{dayan2005theoretical,
  title={Theoretical neuroscience: computational and mathematical modeling of neural systems},
  author={Dayan, Peter and Abbott, Laurence F},
  year={2005},
  publisher={MIT press}
}

@article{hubel1965receptive,
  title={Receptive fields and functional architecture in two nonstriate visual areas (18 and 19) of the cat},
  author={Hubel, David H and Wiesel, Torsten N},
  journal={Journal of neurophysiology},
  year={1965}
}

@article{chichilnisky2001simple,
  title={A simple white noise analysis of neuronal lightresponses},
  author={Chichilnisky, EJ},
  journal={Network: computation in neural systems},
  volume={12},
  number={2},
  pages={199},
  year={2001},
  publisher={IOP Publishing}
}

@article {Talebi1560,
	author = {Talebi, Vargha and Baker, Curtis L.},
	title = {Natural versus Synthetic Stimuli for Estimating Receptive Field Models: A Comparison of Predictive Robustness},
	volume = {32},
	number = {5},
	pages = {1560--1576},
	year = {2012},
	doi = {10.1523/JNEUROSCI.4661-12.2012},
	publisher = {Society for Neuroscience},
	abstract = {An ultimate goal of visual neuroscience is to understand the neural encoding of complex, everyday scenes. Yet most of our knowledge of neuronal receptive fields has come from studies using simple artificial stimuli (e.g., bars, gratings) that may fail to reveal the full nature of a neuron{\textquoteright}s actual response properties. Our goal was to compare the utility of artificial and natural stimuli for estimating receptive field (RF) models. Using extracellular recordings from simple type cells in cat A18, we acquired responses to three types of broadband stimulus ensembles: two widely used artificial patterns (white noise and short bars), and natural images. We used a primary dataset to estimate the spatiotemporal receptive field (STRF) with two hold-back datasets for regularization and validation. STRFs were estimated using an iterative regression algorithm with regularization and subsequently fit with a zero-memory nonlinearity. Each RF model (STRF and zero-memory nonlinearity) was then used in simulations to predict responses to the same stimulus type used to estimate it, as well as to other broadband stimuli and sinewave gratings. White noise stimuli often elicited poor responses leading to noisy RF estimates, while short bars and natural image stimuli were more successful in driving A18 neurons and producing clear RF estimates with strong predictive ability. Natural image-derived RF models were the most robust at predicting responses to other broadband stimulus ensembles that were not used in their estimation and also provided good predictions of tuning curves for sinewave gratings.},
	issn = {0270-6474},
	URL = {https://www.jneurosci.org/content/32/5/1560},
	eprint = {https://www.jneurosci.org/content/32/5/1560.full.pdf},
	journal = {Journal of Neuroscience}
}

@article{sonkusare2019naturalistic,
  title={Naturalistic stimuli in neuroscience: critically acclaimed},
  author={Sonkusare, Saurabh and Breakspear, Michael and Guo, Christine},
  journal={Trends in cognitive sciences},
  volume={23},
  number={8},
  pages={699--714},
  year={2019},
  publisher={Elsevier}
}

@article{lurz2020generalization,
  title={Generalization in data-driven models of primary visual cortex},
  author={Lurz, Konstantin-Klemens and Bashiri, Mohammad and Willeke, Konstantin and Jagadish, Akshay K and Wang, Eric and Walker, Edgar Y and Cadena, Santiago A and Muhammad, Taliah and Cobos, Erick and Tolias, Andreas S and others},
  journal={BioRxiv},
  pages={2020--10},
  year={2020},
  publisher={Cold Spring Harbor Laboratory}
}



@article{annurev:/content/journals/10.1146/annurev-vision-091718-014731,
   author = "Butts, Daniel A.",
   title = "Data-Driven Approaches to Understanding Visual Neuron Activity", 
   journal= "Annual Review of Vision Science",
   year = "2019",
   volume = "5",
   number = "Volume 5, 2019",
   pages = "451-477",
   doi = "https://doi.org/10.1146/annurev-vision-091718-014731",
   url = "https://www.annualreviews.org/content/journals/10.1146/annurev-vision-091718-014731",
   publisher = "Annual Reviews",
   issn = "2374-4650",
   type = "Journal Article",
   keywords = "machine learning",
   keywords = "receptive field",
   keywords = "neural networks",
   keywords = "modeling",
   keywords = "neural coding",
   abstract = "With modern neurophysiological methods able to record neural activity throughout the visual pathway in the context of arbitrarily complex visual stimulation, our understanding of visual system function is becoming limited by the available models of visual neurons that can be directly related to such data. Different forms of statistical models are now being used to probe the cellular and circuit mechanisms shaping neural activity, understand how neural selectivity to complex visual features is computed, and derive the ways in which neurons contribute to systems-level visual processing. However, models that are able to more accurately reproduce observed neural activity often defy simple interpretations. As a result, rather than being used solely to connect with existing theories of visual processing, statistical modeling will increasingly drive the evolution of more sophisticated theories.",
  }

@article{wu2006complete,
  title={Complete functional characterization of sensory neurons by system identification},
  author={Wu, Michael C-K and David, Stephen V and Gallant, Jack L},
  journal={Annu. Rev. Neurosci.},
  volume={29},
  number={1},
  pages={477--505},
  year={2006},
  publisher={Annual Reviews}
}

@book{alpaydin2020introduction,
  title={Introduction to machine learning},
  author={Alpaydin, Ethem},
  year={2020},
  publisher={MIT press}
}

@article{mohanty2012membrane,
  author = {Mohanty, Deepankar and Scholl, Benjamin and Priebe, Nicholas J.},
  title = {The accuracy of membrane potential reconstruction based on spiking receptive fields},
  journal = {Journal of Neurophysiology},
  volume = {107},
  number = {8},
  pages = {2143-2153},
  year = {2012},
  doi = {10.1152/jn.01176.2011},
  note ={PMID: 22279194},
  URL = {https://doi.org/10.1152/jn.01176.2011},
  eprint = {https://doi.org/10.1152/jn.01176.2011}
}

@article{movshon1978receptive,
  author = {Movshon, J A and Thompson, I D and Tolhurst, D J},
  title = {Receptive field organization of complex cells in the cat's striate cortex.},
  journal = {The Journal of Physiology},
  volume = {283},
  number = {1},
  pages = {79-99},
  doi = {https://doi.org/10.1113/jphysiol.1978.sp012489},
  url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1978.sp012489},
  eprint = {https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1978.sp012489},
  abstract = {1. All complex cells in the cat's striate cortex exhibit gross non-linearities of spatial summation when tested with sinusoidal grating stimuli. Their responses to moving gratings of all but the lowest spatial frequencies are usually dominated by a component that is not modulated by the passage of the bars of the grating across the receptive field. They give responses to temporally modulated stationary gratings that consist mostly of even harmonics of the stimulus frequency and that vary little in amplitude or wave form as the spatial phase of the grating is varied. 2. We compared complex cells' receptive fields with their sensitivity to sinusoidal gratings of different spatial frequencies. Qualitatively, the receptive fields are usually two to five times wider than the bars of the gratings that stimulate them most effectively. Quantitatively, the receptive field profiles of complex cells are invariably broader than those predicted by Fourier synthesis of their spatial frequency tuning curves, and in particular lack predicted spatially antagonistic regions. 3. We further examined the receptive field organization of these cells, using pairs of stationary lines flashed synchronously on their receptive fields. If both lines are of the same polarity (bright or dark), complex cells respond to the paired stimulus much less well than they do to either of its component bars, unless the bars are separated by less than about one quarter of the width of the receptive field. If the lines are of opposite polarity, one bright and one dark, the opposite situation obtains: closely spaced bars elicit small responses, while paired bars of larger separation are much more effective. In either case, the results are independent in general character of the absolute positions of the stimuli within the receptive field; rather, they depend in a manner characteristic of each cell on the relative positions of the two bars. 4. The two-line interaction profile that plots the change in a complex cell's response to one bar as a function of the position of a second added bar corresponds closely to the receptive field profile predicted from Fourier synthesis of the cell's spatial frequency tuning curve. These profiles may thus reveal the spatial characteristics of subunits within complex cell-receptive fields. We examined the nature of the interaction between these subunits by performing several two-line interaction experiments in which the onset of the second bar was delayed some time after the onset of the first. The results suggest that neighbouring subunits interact in a facilitatory fashion: for an interval after the presentation of one bar, responses to neighbouring bars are enhanced. 5. The subunits of a complex receptive field may, by their spatial properties, determine the spatial selectivities of complex cells, while the nature of the interaction among the subunits may determine these cells' sensitivity and selectivity for moving visual stimuli...},
  year = {1978}
}

@article{SHAPLEY2009907,
title = {Linear and nonlinear systems analysis of the visual system: Why does it seem so linear?: A review dedicated to the memory of Henk Spekreijse},
journal = {Vision Research},
volume = {49},
number = {9},
pages = {907-921},
year = {2009},
note = {From Retinal and Cortical Circuitry to Clinical Application In memory of Henk Spekreijse - a life dedicated to Vision Research},
issn = {0042-6989},
doi = {https://doi.org/10.1016/j.visres.2008.09.026},
url = {https://www.sciencedirect.com/science/article/pii/S0042698908004653},
author = {Robert Shapley},
keywords = {Retina, Visual pathway, Contrast, Linearity, Visual cortex, System analysis},
abstract = {Linear and nonlinear systems analysis are tools that can be used to study communication systems like the visual system. The first step of systems analysis often is to test whether or not the system is linear. Retinal pathways are surprisingly linear, and some neurons in the visual cortex also emulate linear sensory transducers. We conclude that the retinal linearity depends on specialized ribbon synapses while cortical linearity is the result of balanced excitatory and inhibitory synaptic interactions.}
}

@article{poirazi2003pyramidal,
  title={Pyramidal neuron as two-layer neural network},
  author={Poirazi, Panayiota and Brannon, Terrence and Mel, Bartlett W},
  journal={Neuron},
  volume={37},
  number={6},
  pages={989--999},
  year={2003},
  publisher={Elsevier}
}

@article{baccus2002fast,
  title={Fast and slow contrast adaptation in retinal circuitry},
  author={Baccus, Stephen A and Meister, Markus},
  journal={Neuron},
  volume={36},
  number={5},
  pages={909--919},
  year={2002},
  publisher={Elsevier}
}

@article {Carandini10577,
	author = {Carandini, Matteo and Demb, Jonathan B. and Mante, Valerio and Tolhurst, David J. and Dan, Yang and Olshausen, Bruno A. and Gallant, Jack L. and Rust, Nicole C.},
	title = {Do We Know What the Early Visual System Does?},
	volume = {25},
	number = {46},
	pages = {10577--10597},
	year = {2005},
	doi = {10.1523/JNEUROSCI.3726-05.2005},
	publisher = {Society for Neuroscience},
	abstract = {We can claim that we know what the visual system does once we can predict neural responses to arbitrary stimuli, including those seen in nature. In the early visual system, models based on one or more linear receptive fields hold promise to achieve this goal as long as the models include nonlinear mechanisms that control responsiveness, based on stimulus context and history, and take into account the nonlinearity of spike generation. These linear and nonlinear mechanisms might be the only essential determinants of the response, or alternatively, there may be additional fundamental determinants yet to be identified. Research is progressing with the goals of defining a single {\textquotedblleft}standard model{\textquotedblright} for each stage of the visual pathway and testing the predictive power of these models on the responses to movies of natural scenes. These predictive models represent, at a given stage of the visual pathway, a compact description of visual computation. They would be an invaluable guide for understanding the underlying biophysical and anatomical mechanisms and relating neural responses to visual perception.},
	issn = {0270-6474},
	URL = {https://www.jneurosci.org/content/25/46/10577},
	eprint = {https://www.jneurosci.org/content/25/46/10577.full.pdf},
	journal = {Journal of Neuroscience}
}

@article {Maheswaranathan340943,
	author = {Maheswaranathan, Niru and McIntosh, Lane T. and Tanaka, Hidenori and Grant, Satchel and Kastner, David B. and Melander, Josh B. and Nayebi, Aran and Brezovec, Luke and Wang, Julia and Ganguli, Surya and Baccus, Stephen A.},
	title = {The dynamic neural code of the retina for natural scenes},
	elocation-id = {340943},
	year = {2019},
	doi = {10.1101/340943},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Understanding how the visual system encodes natural scenes is a fundamental goal of sensory neuroscience. We show here that a three-layer network model predicts the retinal response to natural scenes with an accuracy nearing the fundamental limits of predictability. The model{\textquoteright}s internal structure is interpretable, in that model units are highly correlated with interneurons recorded separately and not used to fit the model. We further show the ethological relevance to natural visual processing of a diverse set of phenomena of complex motion encoding, adaptation and predictive coding. Our analysis uncovers a fast timescale of visual processing that is inaccessible directly from experimental data, showing unexpectedly that ganglion cells signal in distinct modes by rapidly (\&lt; 0.1 s) switching their selectivity for direction of motion, orientation, location and the sign of intensity. A new approach that decomposes ganglion cell responses into the contribution of interneurons reveals how the latent effects of parallel retinal circuits generate the response to any possible stimulus. These results reveal extremely flexible and rapid dynamics of the retinal code for natural visual stimuli, explaining the need for a large set of interneuron pathways to generate the dynamic neural code for natural scenes.},
	URL = {https://www.biorxiv.org/content/early/2019/12/17/340943},
	eprint = {https://www.biorxiv.org/content/early/2019/12/17/340943.full.pdf},
	journal = {bioRxiv}
}

@article {Butts11313,
	author = {Butts, Daniel A. and Weng, Chong and Jin, Jianzhong and Alonso, Jose-Manuel and Paninski, Liam},
	title = {Temporal Precision in the Visual Pathway through the Interplay of Excitation and Stimulus-Driven Suppression},
	volume = {31},
	number = {31},
	pages = {11313--11327},
	year = {2011},
	doi = {10.1523/JNEUROSCI.0434-11.2011},
	publisher = {Society for Neuroscience},
	abstract = {Visual neurons can respond with extremely precise temporal patterning to visual stimuli that change on much slower time scales. Here, we investigate how the precise timing of cat thalamic spike trains{\textemdash}which can have timing as precise as 1 ms{\textemdash}is related to the stimulus, in the context of both artificial noise and natural visual stimuli. Using a nonlinear modeling framework applied to extracellular data, we demonstrate that the precise timing of thalamic spike trains can be explained by the interplay between an excitatory input and a delayed suppressive input that resembles inhibition, such that neuronal responses only occur in brief windows where excitation exceeds suppression. The resulting description of thalamic computation resembles earlier models of contrast adaptation, suggesting a more general role for mechanisms of contrast adaptation in visual processing. Thus, we describe a more complex computation underlying thalamic responses to artificial and natural stimuli that has implications for understanding how visual information is represented in the early stages of visual processing.},
	issn = {0270-6474},
	URL = {https://www.jneurosci.org/content/31/31/11313},
	eprint = {https://www.jneurosci.org/content/31/31/11313.full.pdf},
	journal = {Journal of Neuroscience}
}

@article{keat2001predicting,
  title={Predicting every spike: a model for the responses of visual neurons},
  author={Keat, Justin and Reinagel, Pamela and Reid, R Clay and Meister, Markus},
  journal={Neuron},
  volume={30},
  number={3},
  pages={803--817},
  year={2001},
  publisher={Elsevier}
}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}

@article{HORNIK1991251,
title = {Approximation capabilities of multilayer feedforward networks},
journal = {Neural Networks},
volume = {4},
number = {2},
pages = {251-257},
year = {1991},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(91)90009-T},
url = {https://www.sciencedirect.com/science/article/pii/089360809190009T},
author = {Kurt Hornik},
keywords = {Multilayer feedforward networks, Activation function, Universal approximation capabilities, Input environment measure, () approximation, Uniform approximation, Sobolev spaces, Smooth approximation},
abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(μ) performance criteria, for arbitrary finite input environment measures μ, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives.}
}

@article{MAL-006,
url = {http://dx.doi.org/10.1561/2200000006},
year = {2009},
volume = {2},
journal = {Foundations and Trends® in Machine Learning},
title = {Learning Deep Architectures for AI},
doi = {10.1561/2200000006},
issn = {1935-8237},
number = {1},
pages = {1-127},
author = {Yoshua Bengio}
}

@article{Kriegeskorte2015dnn,
   author = "Kriegeskorte, Nikolaus",
   title = "Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing", 
   journal= "Annual Review of Vision Science",
   year = "2015",
   volume = "1",
   number = "Volume 1, 2015",
   pages = "417-446",
   doi = "https://doi.org/10.1146/annurev-vision-082114-035447",
   url = "https://www.annualreviews.org/content/journals/10.1146/annurev-vision-082114-035447",
   publisher = "Annual Reviews",
   issn = "2374-4650",
   type = "Journal Article",
   keywords = "object recognition",
   keywords = "neural network",
   keywords = "biological vision",
   keywords = "computer vision",
   keywords = "artificial intelligence",
   keywords = "computational neuroscience",
   keywords = "deep learning",
   abstract = "Recent advances in neural network modeling have enabled major strides in computer vision and other artificial intelligence applications. Human-level visual recognition abilities are coming within reach of artificial systems. Artificial neural networks are inspired by the brain, and their computations could be implemented in biological neurons. Convolutional feedforward networks, which now dominate computer vision, take further inspiration from the architecture of the primate visual hierarchy. However, the current models are designed with engineering goals, not to model brain computations. Nevertheless, initial studies comparing internal representations between these models and primate brains find surprisingly similar representational spaces. With human-level performance no longer out of reach, we are entering an exciting new era, in which we will be able to build biologically faithful feedforward and recurrent computational models of how biological brains perform high-level feats of intelligence, including vision.",
}

@inproceedings {TensorFlow,
  author = {Mart{\'\i}n Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
  title = {{TensorFlow}: A System for {Large-Scale} Machine Learning},
  booktitle = {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
  year = {2016},
  isbn = {978-1-931971-33-1},
  address = {Savannah, GA},
  pages = {265--283},
  url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
  publisher = {USENIX Association},
  month = nov
}

@article{paszke2017automatic,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{cadena2019conv,
  doi = {10.1371/journal.pcbi.1006897},
  author = {Cadena, Santiago A. AND Denfield, George H. AND Walker, Edgar Y. AND Gatys, Leon A. AND Tolias, Andreas S. AND Bethge, Matthias AND Ecker, Alexander S.},
  journal = {PLOS Computational Biology},
  publisher = {Public Library of Science},
  title = {Deep convolutional models improve predictions of macaque V1 responses to natural images},
  year = {2019},
  month = {04},
  volume = {15},
  url = {https://doi.org/10.1371/journal.pcbi.1006897},
  pages = {1-27},
  abstract = {Despite great efforts over several decades, our best models of primary visual cortex (V1) still predict spiking activity quite poorly when probed with natural stimuli, highlighting our limited understanding of the nonlinear computations in V1. Recently, two approaches based on deep learning have emerged for modeling these nonlinear computations: transfer learning from artificial neural networks trained on object recognition and data-driven convolutional neural network models trained end-to-end on large populations of neurons. Here, we test the ability of both approaches to predict spiking activity in response to natural images in V1 of awake monkeys. We found that the transfer learning approach performed similarly well to the data-driven approach and both outperformed classical linear-nonlinear and wavelet-based feature representations that build on existing theories of V1. Notably, transfer learning using a pre-trained feature space required substantially less experimental time to achieve the same performance. In conclusion, multi-layer convolutional neural networks (CNNs) set the new state of the art for predicting neural responses to natural images in primate V1 and deep features learned for object recognition are better explanations for V1 computation than all previous filter bank theories. This finding strengthens the necessity of V1 models that are multiple nonlinearities away from the image domain and it supports the idea of explaining early visual cortex based on high-level functional goals.},
  number = {4},
}

@misc{kindel2017usingdeeplearningreveal,
  title={Using deep learning to reveal the neural code for images in primary visual cortex}, 
  author={William F. Kindel and Elijah D. Christensen and Joel Zylberberg},
  year={2017},
  eprint={1706.06208},
  archivePrefix={arXiv},
  primaryClass={q-bio.NC},
  url={https://arxiv.org/abs/1706.06208}, 
}

@article{zareh2024deep,
  title={A deep learning model of dorsal and ventral visual streams for DVSD},
  author={Zareh, Masoumeh and Toulabinejad, Elaheh and Manshaei, Mohammad Hossein and Zahabi, Sayed Jalal},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={27464},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{zhang2019convolutional,
  title={Convolutional neural network models of V1 responses to complex patterns},
  author={Zhang, Yimeng and Lee, Tai Sing and Li, Ming and Liu, Fang and Tang, Shiming},
  journal={Journal of computational neuroscience},
  volume={46},
  pages={33--54},
  year={2019},
  publisher={Springer}
}

@article{antolik2016local,
  doi = {10.1371/journal.pcbi.1004927},
  author = {Antolík, Ján AND Hofer, Sonja B. AND Bednar, James A. AND Mrsic-Flogel, Thomas D.},
  journal = {PLOS Computational Biology},
  publisher = {Public Library of Science},
  title = {Model Constrained by Visual Hierarchy Improves Prediction of Neural Responses to Natural Scenes},
  year = {2016},
  month = {06},
  volume = {12},
  url = {https://doi.org/10.1371/journal.pcbi.1004927},
  pages = {1-22},
  abstract = {Accurate estimation of neuronal receptive fields is essential for understanding sensory processing in the early visual system. Yet a full characterization of receptive fields is still incomplete, especially with regard to natural visual stimuli and in complete populations of cortical neurons. While previous work has incorporated known structural properties of the early visual system, such as lateral connectivity, or imposing simple-cell-like receptive field structure, no study has exploited the fact that nearby V1 neurons share common feed-forward input from thalamus and other upstream cortical neurons. We introduce a new method for estimating receptive fields simultaneously for a population of V1 neurons, using a model-based analysis incorporating knowledge of the feed-forward visual hierarchy. We assume that a population of V1 neurons shares a common pool of thalamic inputs, and consists of two layers of simple and complex-like V1 neurons. When fit to recordings of a local population of mouse layer 2/3 V1 neurons, our model offers an accurate description of their response to natural images and significant improvement of prediction power over the current state-of-the-art methods. We show that the responses of a large local population of V1 neurons with locally diverse receptive fields can be described with surprisingly limited number of thalamic inputs, consistent with recent experimental findings. Our structural model not only offers an improved functional characterization of V1 neurons, but also provides a framework for studying the relationship between connectivity and function in visual cortical areas.},
  number = {6},
}

@inproceedings{NIPS2012_c399862d,
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
  pages = {},
  publisher = {Curran Associates, Inc.},
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
  volume = {25},
  year = {2012}
}
